{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d0802a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: done\n",
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      "Platform: osx-arm64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - numpy=1.26\n",
      "    - scikit-learn\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2025.10.5  |       hbd8a1cb_0         152 KB  conda-forge\n",
      "    certifi-2025.10.5          |     pyhd8ed1ab_0         156 KB  conda-forge\n",
      "    openssl-3.5.4              |       h5503f6c_0         2.9 MB  conda-forge\n",
      "    scikit-learn-1.7.2         |  py312h79e0ffc_0         8.5 MB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        11.7 MB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                       2025.8.3-hbd8a1cb_0 --> 2025.10.5-hbd8a1cb_0 \n",
      "  certifi                             2025.8.3-pyhd8ed1ab_0 --> 2025.10.5-pyhd8ed1ab_0 \n",
      "  openssl                                  3.5.3-h5503f6c_0 --> 3.5.4-h5503f6c_0 \n",
      "  scikit-learn       pkgs/main::scikit-learn-1.5.1-py312hd~ --> conda-forge::scikit-learn-1.7.2-py312h79e0ffc_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages:\n",
      "scikit-learn-1.7.2   | 8.5 MB    |                                       |   0% \n",
      "openssl-3.5.4        | 2.9 MB    |                                       |   0% \u001b[A\n",
      "\n",
      "certifi-2025.10.5    | 156 KB    |                                       |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "ca-certificates-2025 | 152 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "certifi-2025.10.5    | 156 KB    | ###7                                  |  10% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "ca-certificates-2025 | 152 KB    | ###8                                  |  11% \u001b[A\u001b[A\u001b[A\n",
      "openssl-3.5.4        | 2.9 MB    | 1                                     |   1% \u001b[A\n",
      "\n",
      "certifi-2025.10.5    | 156 KB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "ca-certificates-2025 | 152 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "certifi-2025.10.5    | 156 KB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "ca-certificates-2025 | 152 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "scikit-learn-1.7.2   | 8.5 MB    |                                       |   0% \u001b[A\n",
      "scikit-learn-1.7.2   | 8.5 MB    | 2                                     |   1% \u001b[A\n",
      "openssl-3.5.4        | 2.9 MB    | ####################################1 |  98% \u001b[A\n",
      "scikit-learn-1.7.2   | 8.5 MB    | #4                                    |   4% \u001b[A\n",
      "                                                                                \u001b[A\n",
      "                                                                                \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install numpy=1.26 scikit-learn -c conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10751460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 2.2.6\n",
      "Uninstalling numpy-2.2.6:\n",
      "  Successfully uninstalled numpy-2.2.6\n",
      "Found existing installation: scikit-learn 1.7.2\n",
      "Uninstalling scikit-learn-1.7.2:\n",
      "  Successfully uninstalled scikit-learn-1.7.2\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.3.4-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.2-cp312-cp312-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.2.6-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Downloading scikit_learn-1.7.2-cp312-cp312-macosx_12_0_arm64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached numpy-2.2.6-cp312-cp312-macosx_14_0_arm64.whl (5.1 MB)\n",
      "Installing collected packages: numpy, scikit-learn\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.6 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\n",
      "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-2.2.6 scikit-learn-1.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall numpy scikit-learn -y\n",
    "!pip install numpy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f88e7ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy<2 in /opt/anaconda3/lib/python3.12/site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"numpy<2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7727663d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic dataset...\n",
      "✓ Dataset saved: 356 grade records\n",
      "\n",
      "Preprocessing data...\n",
      "✓ Features created: 16 features\n",
      "\n",
      "Training model...\n",
      "\n",
      "Model Evaluation:\n",
      "--------------------------------------------------\n",
      "Training Set:\n",
      "  RMSE: 0.4366\n",
      "  MAE:  0.3351\n",
      "  R²:   0.9314\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 1.0402\n",
      "  MAE:  0.8425\n",
      "  R²:   0.6687\n",
      "\n",
      "Top 5 Most Important Features:\n",
      "--------------------------------------------------\n",
      "  cgpa                      0.7826\n",
      "  difficulty_level          0.0538\n",
      "  domain_Networks           0.0235\n",
      "  domain_ML                 0.0196\n",
      "  domain_Web                0.0140\n",
      "\n",
      "Saving model and metadata...\n",
      "✓ Model saved as feature_model.pkl\n",
      "✓ Feature columns saved as feature_columns.json\n",
      "✓ Metadata saved as model_metadata.json\n",
      "\n",
      "==================================================\n",
      "Example Prediction:\n",
      "==================================================\n",
      "Student: S001\n",
      "Course:  C01\n",
      "Predicted Grade: 9.17\n",
      "\n",
      "==================================================\n",
      "Pipeline completed successfully!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# === Step 1: Generate Synthetic Dataset ===\n",
    "print(\"Generating synthetic dataset...\")\n",
    "\n",
    "# Students\n",
    "students = pd.DataFrame({\n",
    "    'student_id': [f\"S{i:04d}\" for i in range(1, 501)],\n",
    "    'branch_code': np.random.choice(['CSE', 'ECE', 'ME', 'CE'], 500),\n",
    "    'cgpa': np.round(np.random.uniform(5, 10, 500), 2)\n",
    "})\n",
    "\n",
    "# Interests\n",
    "domains = ['AI', 'Web', 'DBMS', 'ML', 'Networks']\n",
    "student_interests = []\n",
    "for sid in students['student_id']:\n",
    "    interests = random.sample(domains, np.random.randint(1, 4))\n",
    "    for d in interests:\n",
    "        student_interests.append([sid, d, 1])\n",
    "\n",
    "interests_df = pd.DataFrame(student_interests, columns=['student_id', 'domain', 'interest_level'])\n",
    "\n",
    "# Courses\n",
    "courses = pd.DataFrame({\n",
    "    'course_id': [f\"C{i:02d}\" for i in range(1, 21)],\n",
    "    'domain_tags': np.random.choice(domains, 20),\n",
    "    'difficulty_level': np.random.randint(1, 6, 20)\n",
    "})\n",
    "\n",
    "# Grades\n",
    "grades_records = []\n",
    "for sid in students['student_id']:\n",
    "    taken_courses = np.random.choice(courses['course_id'], np.random.randint(5, 10), replace=False)\n",
    "    student_cgpa = students.loc[students['student_id'] == sid, 'cgpa'].values[0]\n",
    "    student_tags = interests_df[interests_df['student_id'] == sid]['domain'].tolist()\n",
    "    \n",
    "    for c in taken_courses:\n",
    "        course_domain = courses.loc[courses['course_id'] == c, 'domain_tags'].values[0]\n",
    "        interest_bonus = 1 if course_domain in student_tags else 0\n",
    "        grade = np.clip(np.random.normal(student_cgpa + interest_bonus, 1), 5, 10)\n",
    "        grades_records.append([sid, c, round(grade, 2)])\n",
    "\n",
    "student_course_grades = pd.DataFrame(grades_records, columns=['student_id', 'course_id', 'grade'])\n",
    "\n",
    "# Save datasets\n",
    "student_course_grades.to_csv(\"student_course_data.csv\", index=False)\n",
    "students.to_csv(\"students.csv\", index=False)\n",
    "courses.to_csv(\"courses.csv\", index=False)\n",
    "interests_df.to_csv(\"interests.csv\", index=False)\n",
    "print(f\"✓ Dataset saved: {len(student_course_grades)} grade records\")\n",
    "\n",
    "# === Step 2: Preprocess / Feature Encoding ===\n",
    "print(\"\\nPreprocessing data...\")\n",
    "\n",
    "students_encoded = pd.get_dummies(students, columns=['branch_code'], prefix='branch')\n",
    "courses_encoded = pd.get_dummies(courses, columns=['domain_tags'], prefix='domain')\n",
    "\n",
    "data = student_course_grades.merge(students_encoded, on='student_id')\n",
    "data = data.merge(courses_encoded, on='course_id')\n",
    "\n",
    "# Add interest features\n",
    "for domain in domains:\n",
    "    student_interest_domain = interests_df[interests_df['domain'] == domain][['student_id', 'interest_level']].rename(\n",
    "        columns={'interest_level': f'interest_{domain}'}\n",
    "    )\n",
    "    data = data.merge(student_interest_domain, on='student_id', how='left')\n",
    "    data[f'interest_{domain}'] = data[f'interest_{domain}'].fillna(0)\n",
    "\n",
    "print(f\"✓ Features created: {data.shape[1] - 3} features\")  # Exclude student_id, course_id, grade\n",
    "\n",
    "# === Step 3: Train Feature-based Model ===\n",
    "print(\"\\nTraining model...\")\n",
    "\n",
    "# Define feature columns dynamically\n",
    "branch_cols = [col for col in data.columns if col.startswith('branch_')]\n",
    "domain_cols = [col for col in data.columns if col.startswith('domain_')]\n",
    "interest_cols = [col for col in data.columns if col.startswith('interest_')]\n",
    "\n",
    "feature_cols = ['cgpa', 'difficulty_level'] + branch_cols + domain_cols + interest_cols\n",
    "\n",
    "X = data[feature_cols]\n",
    "y = data['grade']\n",
    "\n",
    "# Split data for validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "feature_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "feature_model.fit(X_train, y_train)\n",
    "\n",
    "# === Step 4: Evaluate Model ===\n",
    "print(\"\\nModel Evaluation:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Training performance\n",
    "train_pred = feature_model.predict(X_train)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, train_pred))\n",
    "train_mae = mean_absolute_error(y_train, train_pred)\n",
    "train_r2 = r2_score(y_train, train_pred)\n",
    "\n",
    "print(f\"Training Set:\")\n",
    "print(f\"  RMSE: {train_rmse:.4f}\")\n",
    "print(f\"  MAE:  {train_mae:.4f}\")\n",
    "print(f\"  R²:   {train_r2:.4f}\")\n",
    "\n",
    "# Testing performance\n",
    "test_pred = feature_model.predict(X_test)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, test_pred))\n",
    "test_mae = mean_absolute_error(y_test, test_pred)\n",
    "test_r2 = r2_score(y_test, test_pred)\n",
    "\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  RMSE: {test_rmse:.4f}\")\n",
    "print(f\"  MAE:  {test_mae:.4f}\")\n",
    "print(f\"  R²:   {test_r2:.4f}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': feature_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 5 Most Important Features:\")\n",
    "print(\"-\" * 50)\n",
    "for idx, row in feature_importance.head().iterrows():\n",
    "    print(f\"  {row['feature']:<25} {row['importance']:.4f}\")\n",
    "\n",
    "# === Step 5: Save Model and Metadata ===\n",
    "print(\"\\nSaving model and metadata...\")\n",
    "\n",
    "# Save model\n",
    "with open(\"feature_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(feature_model, f)\n",
    "\n",
    "# Save feature names for inference\n",
    "with open(\"feature_columns.json\", \"w\") as f:\n",
    "    json.dump(feature_cols, f)\n",
    "\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    \"model_type\": \"RandomForestRegressor\",\n",
    "    \"n_estimators\": 100,\n",
    "    \"features\": feature_cols,\n",
    "    \"training_samples\": len(X_train),\n",
    "    \"test_samples\": len(X_test),\n",
    "    \"test_rmse\": float(test_rmse),\n",
    "    \"test_mae\": float(test_mae),\n",
    "    \"test_r2\": float(test_r2),\n",
    "    \"domains\": domains\n",
    "}\n",
    "\n",
    "with open(\"model_metadata.json\", \"w\") as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(\"✓ Model saved as feature_model.pkl\")\n",
    "print(\"✓ Feature columns saved as feature_columns.json\")\n",
    "print(\"✓ Metadata saved as model_metadata.json\")\n",
    "\n",
    "# === Step 6: Example Prediction Function ===\n",
    "def predict_grade(student_id, course_id):\n",
    "    \"\"\"\n",
    "    Predict grade for a student-course pair\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    student_info = students[students['student_id'] == student_id].iloc[0]\n",
    "    course_info = courses[courses['course_id'] == course_id].iloc[0]\n",
    "    student_interests_list = interests_df[interests_df['student_id'] == student_id]['domain'].tolist()\n",
    "    \n",
    "    # Create feature vector\n",
    "    features = {\n",
    "        'cgpa': student_info['cgpa'],\n",
    "        'difficulty_level': course_info['difficulty_level']\n",
    "    }\n",
    "    \n",
    "    # Branch encoding\n",
    "    for branch in ['CE', 'CSE', 'ECE', 'ME']:\n",
    "        features[f'branch_{branch}'] = 1 if student_info['branch_code'] == branch else 0\n",
    "    \n",
    "    # Domain encoding\n",
    "    for domain in domains:\n",
    "        features[f'domain_{domain}'] = 1 if course_info['domain_tags'] == domain else 0\n",
    "    \n",
    "    # Interest encoding\n",
    "    for domain in domains:\n",
    "        features[f'interest_{domain}'] = 1 if domain in student_interests_list else 0\n",
    "    \n",
    "    # Create DataFrame with correct column order\n",
    "    feature_vector = pd.DataFrame([features])[feature_cols]\n",
    "    \n",
    "    # Predict\n",
    "    predicted_grade = feature_model.predict(feature_vector)[0]\n",
    "    \n",
    "    return predicted_grade\n",
    "\n",
    "# Example prediction\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Example Prediction:\")\n",
    "print(\"=\" * 50)\n",
    "example_student = students['student_id'].iloc[0]\n",
    "example_course = courses['course_id'].iloc[0]\n",
    "predicted = predict_grade(example_student, example_course)\n",
    "print(f\"Student: {example_student}\")\n",
    "print(f\"Course:  {example_course}\")\n",
    "print(f\"Predicted Grade: {predicted:.2f}\")\n",
    "\n",
    "# Check if actual grade exists\n",
    "actual = data[(data['student_id'] == example_student) & (data['course_id'] == example_course)]\n",
    "if not actual.empty:\n",
    "    print(f\"Actual Grade:    {actual['grade'].values[0]:.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Pipeline completed successfully!\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f7375d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
